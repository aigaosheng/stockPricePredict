{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "91a6bf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "target_symbol = 'TQQQ'\n",
    "cache_file = './TQQQ_stock_cache_feature.pkl'\n",
    "with open(cache_file, 'rb') as fi:\n",
    "    data_feature = pickle.load(fi)\n",
    "\n",
    "cache_raw_file = './TQQQ_stock_cache.pkl'\n",
    "with open(cache_raw_file, 'rb') as fi:\n",
    "    data_raw = pickle.load(fi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "26dfabbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TQQQ':             label_1       Open       High        Low      Close  Adj Close  \\\n",
       " Date                                                                         \n",
       " 2010-02-11      0.0   0.405858   0.433809   0.404560   0.431471   0.431471   \n",
       " 2010-02-12      1.0   0.419729   0.436978   0.417288   0.433238   0.433238   \n",
       " 2010-02-16      1.0   0.443420   0.451058   0.436459   0.450019   0.450019   \n",
       " 2010-02-17      1.0   0.456046   0.457759   0.449188   0.457656   0.457656   \n",
       " 2010-02-18      0.0   0.457188   0.469085   0.454435   0.466332   0.466332   \n",
       " ...             ...        ...        ...        ...        ...        ...   \n",
       " 2022-09-30      1.0  20.160000  21.090000  19.280001  19.320000  19.320000   \n",
       " 2022-10-03      1.0  19.700001  21.010000  19.360001  20.660000  20.660000   \n",
       " 2022-10-04      0.0  21.900000  22.770000  21.889999  22.580000  22.580000   \n",
       " 2022-10-05      2.0  21.670000  23.000000  21.010000  22.580000  22.580000   \n",
       " 2022-10-06      2.0  22.299999  23.059999  21.920000  22.010000  22.010000   \n",
       " \n",
       "                Volume  label  \n",
       " Date                          \n",
       " 2010-02-11    3456000    0.0  \n",
       " 2010-02-12    8601600    1.0  \n",
       " 2010-02-16    9619200    1.0  \n",
       " 2010-02-17   19180800    1.0  \n",
       " 2010-02-18   38860800    0.0  \n",
       " ...               ...    ...  \n",
       " 2022-09-30  255119700    1.0  \n",
       " 2022-10-03  223611300    1.0  \n",
       " 2022-10-04  231661800    0.0  \n",
       " 2022-10-05  229199500    2.0  \n",
       " 2022-10-06  237543600    2.0  \n",
       " \n",
       " [3186 rows x 8 columns],\n",
       " 'DX-Y.NYB':             label_1        Open        High         Low       Close  \\\n",
       " Date                                                                  \n",
       " 1971-01-04      0.0  120.529999  120.529999  120.529999  120.529999   \n",
       " 1971-01-05      0.0  120.519997  120.519997  120.519997  120.519997   \n",
       " 1971-01-06      0.0  120.489998  120.489998  120.489998  120.489998   \n",
       " 1971-01-07      0.0  120.550003  120.550003  120.550003  120.550003   \n",
       " 1971-01-08      0.0  120.529999  120.529999  120.529999  120.529999   \n",
       " ...             ...         ...         ...         ...         ...   \n",
       " 2022-09-30      0.0  111.750000  112.669998  111.580002  112.120003   \n",
       " 2022-10-03      2.0  112.169998  112.540001  111.470001  111.750000   \n",
       " 2022-10-04      0.0  111.589996  111.889999  110.059998  110.070000   \n",
       " 2022-10-05      1.0  110.230003  111.739998  110.089996  111.070000   \n",
       " 2022-10-06      0.0  111.019997  112.309998  110.779999  112.260002   \n",
       " \n",
       "              Adj Close  Volume  label  \n",
       " Date                                   \n",
       " 1971-01-04  120.529999       0    0.0  \n",
       " 1971-01-05  120.519997       0    0.0  \n",
       " 1971-01-06  120.489998       0    0.0  \n",
       " 1971-01-07  120.550003       0    0.0  \n",
       " 1971-01-08  120.529999       0    0.0  \n",
       " ...                ...     ...    ...  \n",
       " 2022-09-30  112.120003       0    0.0  \n",
       " 2022-10-03  111.750000       0    2.0  \n",
       " 2022-10-04  110.070000       0    0.0  \n",
       " 2022-10-05  111.070000       0    1.0  \n",
       " 2022-10-06  112.260002       0    0.0  \n",
       " \n",
       " [13157 rows x 8 columns],\n",
       " '^VIX':             label_1       Open       High        Low      Close  Adj Close  \\\n",
       " Date                                                                         \n",
       " 1990-01-02      1.0  17.240000  17.240000  17.240000  17.240000  17.240000   \n",
       " 1990-01-03      1.0  18.190001  18.190001  18.190001  18.190001  18.190001   \n",
       " 1990-01-04      1.0  19.219999  19.219999  19.219999  19.219999  19.219999   \n",
       " 1990-01-05      0.0  20.110001  20.110001  20.110001  20.110001  20.110001   \n",
       " 1990-01-08      1.0  20.260000  20.260000  20.260000  20.260000  20.260000   \n",
       " ...             ...        ...        ...        ...        ...        ...   \n",
       " 2022-09-30      2.0  31.610001  33.250000  29.389999  31.620001  31.620001   \n",
       " 2022-10-03      2.0  33.000000  33.060001  29.629999  30.100000  30.100000   \n",
       " 2022-10-04      2.0  29.520000  29.620001  28.559999  29.070000  29.070000   \n",
       " 2022-10-05      1.0  29.360001  30.110001  28.500000  28.549999  28.549999   \n",
       " 2022-10-06      1.0  28.600000  30.740000  28.559999  30.520000  30.520000   \n",
       " \n",
       "             Volume  label  \n",
       " Date                       \n",
       " 1990-01-02       0    1.0  \n",
       " 1990-01-03       0    1.0  \n",
       " 1990-01-04       0    1.0  \n",
       " 1990-01-05       0    0.0  \n",
       " 1990-01-08       0    1.0  \n",
       " ...            ...    ...  \n",
       " 2022-09-30       0    2.0  \n",
       " 2022-10-03       0    2.0  \n",
       " 2022-10-04       0    2.0  \n",
       " 2022-10-05       0    1.0  \n",
       " 2022-10-06       0    1.0  \n",
       " \n",
       " [8256 rows x 8 columns]}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dc5e86e3-c56e-4eb7-8b95-a3c1541d7ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                     | 0/3 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:hyperopt.fmin:job exception: catboost/libs/metrics/metric.cpp:6252: Eval metric should have a single value. Metric F1 provides a value for each class, thus it cannot be used as a single value to select best iteration or to detect overfitting. If you just want to look on the values of this metric use custom_metric parameter.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                     | 0/3 [00:00<?, ?trial/s, best loss=?]\n"
     ]
    },
    {
     "ename": "CatBoostError",
     "evalue": "catboost/libs/metrics/metric.cpp:6252: Eval metric should have a single value. Metric F1 provides a value for each class, thus it cannot be used as a single value to select best iteration or to detect overfitting. If you just want to look on the values of this metric use custom_metric parameter.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCatBoostError\u001b[0m                             Traceback (most recent call last)",
      "Input \u001b[0;32mIn [55]\u001b[0m, in \u001b[0;36m<cell line: 172>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    167\u001b[0m     tuning_report[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetric\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdev\u001b[39m\u001b[38;5;124m'\u001b[39m: dev_acc})\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tuning_report\n\u001b[0;32m--> 172\u001b[0m \u001b[43mmodelHyperOptTuning\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTQQQ\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_feature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_raw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./catboost_dev.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_model\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./catboost_model.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtune_obj_reward\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mn_stake\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcash_capital\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [55]\u001b[0m, in \u001b[0;36mmodelHyperOptTuning\u001b[0;34m(target_symbol, train_dev_eval_set, data_raw, o_prediction_file, save_model, tune_obj_reward)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m ntry \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m3\u001b[39m):\n\u001b[1;32m    113\u001b[0m             opt_trials \u001b[38;5;241m=\u001b[39m Trials()\n\u001b[0;32m--> 114\u001b[0m             best \u001b[38;5;241m=\u001b[39m \u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m                \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel_cost\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m                \u001b[49m\u001b[43mspace\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msearch_space\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m                \u001b[49m\u001b[43malgo\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtpe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuggest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m                \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m                \u001b[49m\u001b[43mtrials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopt_trials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m        \u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;66;03m#             logging.info(infome(__file__, '*** XGB MODEL tuinig *** '))\u001b[39;00m\n\u001b[1;32m    122\u001b[0m             best_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(opt_trials\u001b[38;5;241m.\u001b[39mresults, key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m v: v[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/gs-KL75tqvG/lib/python3.8/site-packages/hyperopt/fmin.py:540\u001b[0m, in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    537\u001b[0m     fn \u001b[38;5;241m=\u001b[39m __objective_fmin_wrapper(fn)\n\u001b[1;32m    539\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m allow_trials_fmin \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(trials, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfmin\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 540\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrials\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    541\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    542\u001b[0m \u001b[43m        \u001b[49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    543\u001b[0m \u001b[43m        \u001b[49m\u001b[43malgo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malgo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    547\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_queue_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    548\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrstate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrstate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    549\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    552\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_argmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_argmin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    553\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progressbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progressbar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    554\u001b[0m \u001b[43m        \u001b[49m\u001b[43mearly_stop_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stop_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    555\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrials_save_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrials_save_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trials \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    559\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(trials_save_file):\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/gs-KL75tqvG/lib/python3.8/site-packages/hyperopt/base.py:671\u001b[0m, in \u001b[0;36mTrials.fmin\u001b[0;34m(self, fn, space, algo, max_evals, timeout, loss_threshold, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[38;5;66;03m# -- Stop-gap implementation!\u001b[39;00m\n\u001b[1;32m    667\u001b[0m \u001b[38;5;66;03m#    fmin should have been a Trials method in the first place\u001b[39;00m\n\u001b[1;32m    668\u001b[0m \u001b[38;5;66;03m#    but for now it's still sitting in another file.\u001b[39;00m\n\u001b[1;32m    669\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfmin\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fmin\n\u001b[0;32m--> 671\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m    \u001b[49m\u001b[43malgo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malgo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrstate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrstate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_trials_fmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# -- prevent recursion\u001b[39;49;00m\n\u001b[1;32m    683\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    684\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_argmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_argmin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_progressbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progressbar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    687\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stop_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stop_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrials_save_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrials_save_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/gs-KL75tqvG/lib/python3.8/site-packages/hyperopt/fmin.py:586\u001b[0m, in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    583\u001b[0m rval\u001b[38;5;241m.\u001b[39mcatch_eval_exceptions \u001b[38;5;241m=\u001b[39m catch_eval_exceptions\n\u001b[1;32m    585\u001b[0m \u001b[38;5;66;03m# next line is where the fmin is actually executed\u001b[39;00m\n\u001b[0;32m--> 586\u001b[0m \u001b[43mrval\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexhaust\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_argmin:\n\u001b[1;32m    589\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(trials\u001b[38;5;241m.\u001b[39mtrials) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/gs-KL75tqvG/lib/python3.8/site-packages/hyperopt/fmin.py:364\u001b[0m, in \u001b[0;36mFMinIter.exhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexhaust\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    363\u001b[0m     n_done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials)\n\u001b[0;32m--> 364\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_done\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblock_until_done\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masynchronous\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    365\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials\u001b[38;5;241m.\u001b[39mrefresh()\n\u001b[1;32m    366\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/gs-KL75tqvG/lib/python3.8/site-packages/hyperopt/fmin.py:300\u001b[0m, in \u001b[0;36mFMinIter.run\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    297\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpoll_interval_secs)\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;66;03m# -- loop over trials and do the jobs directly\u001b[39;00m\n\u001b[0;32m--> 300\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserial_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials\u001b[38;5;241m.\u001b[39mrefresh()\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials_save_file \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/gs-KL75tqvG/lib/python3.8/site-packages/hyperopt/fmin.py:178\u001b[0m, in \u001b[0;36mFMinIter.serial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m    176\u001b[0m ctrl \u001b[38;5;241m=\u001b[39m base\u001b[38;5;241m.\u001b[39mCtrl(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials, current_trial\u001b[38;5;241m=\u001b[39mtrial)\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 178\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdomain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctrl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    180\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjob exception: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mstr\u001b[39m(e))\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/gs-KL75tqvG/lib/python3.8/site-packages/hyperopt/base.py:892\u001b[0m, in \u001b[0;36mDomain.evaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    884\u001b[0m     \u001b[38;5;66;03m# -- the \"work\" of evaluating `config` can be written\u001b[39;00m\n\u001b[1;32m    885\u001b[0m     \u001b[38;5;66;03m#    either into the pyll part (self.expr)\u001b[39;00m\n\u001b[1;32m    886\u001b[0m     \u001b[38;5;66;03m#    or the normal Python part (self.fn)\u001b[39;00m\n\u001b[1;32m    887\u001b[0m     pyll_rval \u001b[38;5;241m=\u001b[39m pyll\u001b[38;5;241m.\u001b[39mrec_eval(\n\u001b[1;32m    888\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpr,\n\u001b[1;32m    889\u001b[0m         memo\u001b[38;5;241m=\u001b[39mmemo,\n\u001b[1;32m    890\u001b[0m         print_node_on_error\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrec_eval_print_node_on_error,\n\u001b[1;32m    891\u001b[0m     )\n\u001b[0;32m--> 892\u001b[0m     rval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpyll_rval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rval, (\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mint\u001b[39m, np\u001b[38;5;241m.\u001b[39mnumber)):\n\u001b[1;32m    895\u001b[0m     dict_rval \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(rval), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m\"\u001b[39m: STATUS_OK}\n",
      "Input \u001b[0;32mIn [55]\u001b[0m, in \u001b[0;36mmodelHyperOptTuning.<locals>.model_cost\u001b[0;34m(model_cfg)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[38;5;66;03m# print(catboost_cfg)\u001b[39;00m\n\u001b[1;32m     75\u001b[0m         model_now \u001b[38;5;241m=\u001b[39m CatBoostClassifier(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcatboost_cfg)\n\u001b[0;32m---> 76\u001b[0m         \u001b[43mmodel_now\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_dev\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_dev\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;66;03m#, early_stopping_rounds=50, verbose=True)\u001b[39;00m\n\u001b[1;32m     77\u001b[0m         y_dev_pred \u001b[38;5;241m=\u001b[39m model_now\u001b[38;5;241m.\u001b[39mpredict(x_dev)\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m#         dev_result = model_now.evals_result()\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m#         dev_acc = dev_result['validation_0'][eval_metric][0]\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/gs-KL75tqvG/lib/python3.8/site-packages/catboost/core.py:5007\u001b[0m, in \u001b[0;36mCatBoostClassifier.fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   5004\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss_function\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[1;32m   5005\u001b[0m     CatBoostClassifier\u001b[38;5;241m.\u001b[39m_check_is_compatible_loss(params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss_function\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m-> 5007\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_best_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5008\u001b[0m \u001b[43m          \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogging_level\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn_description\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_period\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5009\u001b[0m \u001b[43m          \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_snapshot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_interval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_cout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_cerr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5010\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/gs-KL75tqvG/lib/python3.8/site-packages/catboost/core.py:2278\u001b[0m, in \u001b[0;36mCatBoost._fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   2274\u001b[0m allow_clear_pool \u001b[38;5;241m=\u001b[39m train_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_clear_pool\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   2276\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m log_fixup(log_cout, log_cerr), \\\n\u001b[1;32m   2277\u001b[0m     plot_wrapper(plot, [_get_train_dir(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_params())]):\n\u001b[0;32m-> 2278\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_pool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meval_sets\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2281\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2282\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_clear_pool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2283\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minit_model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m   2284\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2286\u001b[0m \u001b[38;5;66;03m# Have property feature_importance possibly set\u001b[39;00m\n\u001b[1;32m   2287\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_object\u001b[38;5;241m.\u001b[39m_get_loss_function_name()\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/gs-KL75tqvG/lib/python3.8/site-packages/catboost/core.py:1705\u001b[0m, in \u001b[0;36m_CatBoostBase._train\u001b[0;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[1;32m   1704\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_train\u001b[39m(\u001b[38;5;28mself\u001b[39m, train_pool, test_pool, params, allow_clear_pool, init_model):\n\u001b[0;32m-> 1705\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_object\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_clear_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_object\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1706\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_trained_model_attributes()\n",
      "File \u001b[0;32m_catboost.pyx:4585\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_catboost.pyx:4634\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mCatBoostError\u001b[0m: catboost/libs/metrics/metric.cpp:6252: Eval metric should have a single value. Metric F1 provides a value for each class, thus it cannot be used as a single value to select best iteration or to detect overfitting. If you just want to look on the values of this metric use custom_metric parameter."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from prepareMLdata import prepareStockLabel\n",
    "import pickle\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier, Pool, cv\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from hyperopt import tpe, hp, fmin, Trials\n",
    "import copy\n",
    "from mlStrategyLongshort import strategyEvaluate\n",
    "import logging\n",
    "from melog import infome\n",
    "from mlPredict import dataSplit, acc_metric, error_metric, balanceLabel\n",
    "\n",
    "def modelHyperOptTuning(target_symbol, train_dev_eval_set, data_raw, o_prediction_file, save_model = './xgb_model.json', tune_obj_reward = {'n_stake':1, 'cash_capital':1000}):\n",
    "    '''\n",
    "    Desc: tune ML model\n",
    "\n",
    "    train_dev_eval_set: input train/dev/test data set\n",
    "\n",
    "    '''\n",
    "    tuning_report = {}\n",
    "\n",
    "    #step-1: model training\n",
    "    #prepare training data\n",
    "    train_dev_eval_set['train'], is_binary = balanceLabel(train_dev_eval_set['train'])\n",
    "    # train_dev_eval_set['dev'],is_binary = balanceLabel(train_dev_eval_set['dev'])\n",
    "\n",
    "    feat_cols = list(filter(lambda x: x != 'label', train_dev_eval_set['train'].columns))\n",
    "    label_cols = 'label'\n",
    "\n",
    "    x_train = train_dev_eval_set['train'][feat_cols].to_numpy()\n",
    "    y_train = train_dev_eval_set['train'][label_cols].to_numpy().astype(int)\n",
    "\n",
    "    x_dev = train_dev_eval_set['dev'][feat_cols].to_numpy()\n",
    "    y_dev = train_dev_eval_set['dev'][label_cols].to_numpy().astype(int)\n",
    "\n",
    "    eval_set_df = train_dev_eval_set['dev']\n",
    "    o_prediction_file = './opt_model_dev.csv'\n",
    "    \n",
    "#     is_binary = False\n",
    "    if is_binary:\n",
    "        loss_function = 'LogLoss'\n",
    "        eval_metric = 'Accuracy'\n",
    "    else:\n",
    "        loss_function = 'MultiClass'\n",
    "        eval_metric = 'TotalF1' # 'Accuracy' #F1\n",
    "    \n",
    "    base_catboost_cfg = {\n",
    "        'iterations': 0,\n",
    "        'loss_function' : loss_function,\n",
    "        # 'cat_features' : [],\n",
    "        'use_best_model': True,\n",
    "        'verbose': False,\n",
    "        'learning_rate': 0.01,\n",
    "        'l2_leaf_reg' : 0,\n",
    "    #     reg_alpha = 10,\n",
    "        'depth': 0,\n",
    "        'eval_metric' : eval_metric, #'auc', #'merror', #'mlogloss',\n",
    "\n",
    "    }\n",
    "\n",
    "    def model_cost(model_cfg):\n",
    "        catboost_cfg = copy.deepcopy(base_catboost_cfg)\n",
    "        catboost_cfg.update(\n",
    "            {\n",
    "            'iterations': model_cfg['iterations'],\n",
    "            'learning_rate': model_cfg['learning_rate'],\n",
    "            'l2_leaf_reg' : model_cfg['l2_leaf_reg'],\n",
    "            'depth': model_cfg['depth'],\n",
    "        }\n",
    "        )\n",
    "        # print(catboost_cfg)\n",
    "        model_now = CatBoostClassifier(**catboost_cfg)\n",
    "        model_now.fit(x_train, y_train, eval_set = [(x_dev, y_dev)])#, early_stopping_rounds=50, verbose=True)\n",
    "        y_dev_pred = model_now.predict(x_dev)\n",
    "#         dev_result = model_now.evals_result()\n",
    "#         dev_acc = dev_result['validation_0'][eval_metric][0]\n",
    "        dev_acc = acc_metric(y_dev_pred, y_dev)\n",
    "\n",
    "        #model predict in dev\n",
    "        feat_cols = list(filter(lambda x: x != 'label', eval_set_df.columns))\n",
    "        label_cols = 'label' \n",
    "        #evaluate set\n",
    "        x_eval = eval_set_df[feat_cols].to_numpy()\n",
    "        y_eval = eval_set_df[label_cols].to_numpy().astype(int)\n",
    "        y_eval_pred = model_now.predict(x_eval)\n",
    "        y_eval_pred_df = pd.DataFrame(eval_set_df['label'])\n",
    "        y_eval_pred_df['predict'] = y_eval_pred\n",
    "        #Save prediction \n",
    "        o_cols = ['Open', 'High', 'Low','Close', 'Adj Close', 'Volume',]\n",
    "        \n",
    "        o_test = data_raw[target_symbol].loc[y_eval_pred_df.index][o_cols]\n",
    "        o_test['openinterest'] = 0\n",
    "        o_test = pd.merge(o_test, y_eval_pred_df['predict'], on='Date', how='inner')\n",
    "        o_test.to_csv(o_prediction_file, index = True)\n",
    "        reward_gain = strategyEvaluate(target_symbol, o_prediction_file, n_stake=1, cash_capital= 100, is_model_opt=True)\n",
    "\n",
    "        return -reward_gain #dev_acc #\n",
    "\n",
    "    search_space = {\n",
    "        'iterations': hp.randint('iterations', 5, 100),\n",
    "        'learning_rate': hp.uniform('learning_rate', 0.01, 1),\n",
    "        'depth': hp.randint('depth', 2, 8),\n",
    "        'l2_leaf_reg': hp.randint('l2_leaf_reg', 1, 10),\n",
    "    }\n",
    "    best_model = None\n",
    "    best_model_val = None\n",
    "    n_cycle = 0\n",
    "    while(True):\n",
    "        for ntry in range(3):\n",
    "            opt_trials = Trials()\n",
    "            best = fmin(\n",
    "                fn = model_cost,\n",
    "                space = search_space,\n",
    "                algo = tpe.suggest,\n",
    "                max_evals = 3,\n",
    "                trials=opt_trials,        \n",
    "            )\n",
    "#             logging.info(infome(__file__, '*** XGB MODEL tuinig *** '))\n",
    "            best_value = sorted(opt_trials.results, key = lambda v: v['loss'])\n",
    "#             logging.info(infome(__file__, f'best = {best}, {best_value[0]} '))\n",
    "\n",
    "            if best_model:\n",
    "                if best_value[0]['loss'] < best_model_val['loss']:\n",
    "                    best_model_val = best_value[0]\n",
    "                    best_model = best\n",
    "            else:\n",
    "                best_model_val = best_value[0]\n",
    "                best_model = best\n",
    "\n",
    "            print(f'**** This is {ntry}-th try, {best}')\n",
    "        if best_value[0]['loss'] < 0.0 or n_cycle >=3:\n",
    "            break\n",
    "        n_cycle += 1\n",
    "\n",
    "    catboost_cfg = copy.deepcopy(base_catboost_cfg)\n",
    "    catboost_cfg.update(\n",
    "        {\n",
    "        'iterations': best_model['iterations'],\n",
    "        'learning_rate': best_model['learning_rate'],\n",
    "        'l2_leaf_reg' : best_model['l2_leaf_reg'],\n",
    "        'depth': best_model['depth'],\n",
    "    }\n",
    "    )\n",
    "    print(catboost_cfg)\n",
    "    model_now = CatBoostClassifier(**catboost_cfg)\n",
    "    model_now.fit(x_train, y_train, eval_set = [(x_dev, y_dev)])#, early_stopping_rounds=50, verbose=True)\n",
    " \n",
    "    model_now.save_model(save_model)\n",
    "    \n",
    "    # #report\n",
    "    tuning_report['model'] = 'catboost'\n",
    "    tuning_report['param'] = catboost_cfg\n",
    "\n",
    "    #evaluate model\n",
    "    model_now.load_model(save_model)\n",
    "    y_train_pred = model_now.predict(x_train)\n",
    "    acc = acc_metric(y_train_pred, y_train)\n",
    "    print(f'train = {acc}')\n",
    "    tuning_report['metric'] = {'train': acc}\n",
    "    \n",
    "    y_dev_pred = model_now.predict(x_dev)\n",
    "    dev_acc = acc_metric(y_dev_pred, y_dev)\n",
    "    print(f'dev = {dev_acc}')\n",
    "    tuning_report['metric'].update({'dev': dev_acc})\n",
    " \n",
    "\n",
    "    return tuning_report\n",
    "\n",
    "modelHyperOptTuning('TQQQ', data_feature, data_raw, './catboost_dev.csv', save_model = './catboost_model.json', tune_obj_reward = {'n_stake':1, 'cash_capital':1000})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4880f3c9-243a-4554-aba8-cdf3ab653583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2018-12-31', '2019-01-02', '2019-01-03', '2019-01-04',\n",
      "               '2019-01-07', '2019-01-08', '2019-01-09', '2019-01-10',\n",
      "               '2019-01-11', '2019-01-14',\n",
      "               ...\n",
      "               '2020-03-19', '2020-03-20', '2020-03-23', '2020-03-24',\n",
      "               '2020-03-25', '2020-03-26', '2020-03-27', '2020-03-30',\n",
      "               '2020-03-31', '2020-04-01'],\n",
      "              dtype='datetime64[ns]', name='Date', length=316, freq=None)\n"
     ]
    }
   ],
   "source": [
    "# print(feat_data2['price_mid'].head(3))\n",
    "# print(feat_data2['price_mid'].shift(-1).head(3))\n",
    "# a=feat_data2['price_mid'].shift(-1)-feat_data2['price_mid']\n",
    "print(data_feat_hist['dev'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2a499fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███| 100/100 [00:00<00:00, 501.22trial/s, best loss: 0.0026426603445583396]\n",
      "{'x': 0.051406812238830174}\n",
      "****\n",
      "{'loss': 0.0026426603445583396, 'status': 'ok', 'eval_time': 1665208408.1580944, 'other_stuff': {'type': None, 'value': [0, 1, 2]}}\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import time\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "\n",
    "def objective(x):\n",
    "    return {\n",
    "        'loss': x ** 2,\n",
    "        'status': STATUS_OK,\n",
    "        # -- store other results like this\n",
    "        'eval_time': time.time(),\n",
    "        'other_stuff': {'type': None, 'value': [0, 1, 2]},\n",
    "        # -- attachments are handled differently\n",
    "        'attachments':\n",
    "            {'time_module': pickle.dumps(time.time)}\n",
    "        }\n",
    "trials = Trials()\n",
    "best = fmin(objective,\n",
    "    space=hp.uniform('x', -10, 10),\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=100,\n",
    "    trials=trials)\n",
    "print(best)\n",
    "print('****')\n",
    "# print(trials.results)\n",
    "d = sorted(trials.results, key = lambda v: v['loss'])\n",
    "print(d[0])\n",
    "# print(trials.trials[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "46de4c5b-a93b-41d8-8830-a331a2a57a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_metric(y1, y2):\n",
    "    '''\n",
    "    Calculate accuracy\n",
    "    '''\n",
    "    res = list(zip(y1, y2))\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for v in res:\n",
    "        correct += (v[0]-v[1]) * (v[0]-v[1])\n",
    "\n",
    "    return math.sqrt(correct/float(len(res)))\n",
    "\n",
    "\n",
    "def modelHyperOptTuningRegression(target_symbol, train_dev_eval_set, data_raw, o_prediction_file, save_model = './xgb_model_debug.json'):\n",
    "    '''\n",
    "    Desc: tune ML model\n",
    "\n",
    "    train_dev_eval_set: input train/dev/test data set\n",
    "\n",
    "    '''\n",
    "    tuning_report = {}\n",
    "\n",
    "    #step-1: model training\n",
    "    #prepare training data\n",
    "    # train_dev_eval_set['train'] = balanceLabel(train_dev_eval_set['train'])\n",
    "    # train_dev_eval_set['dev'] = balanceLabel(train_dev_eval_set['dev'])\n",
    "\n",
    "    feat_cols = list(filter(lambda x: x != 'label', train_dev_eval_set['train'].columns))\n",
    "    label_cols = 'label'\n",
    "\n",
    "    x_train = train_dev_eval_set['train'][feat_cols].to_numpy()\n",
    "    y_train = train_dev_eval_set['train'][label_cols].to_numpy()#.astype(int)\n",
    "\n",
    "    x_dev = train_dev_eval_set['dev'][feat_cols].to_numpy()\n",
    "    y_dev = train_dev_eval_set['dev'][label_cols].to_numpy()#.astype(int)\n",
    "\n",
    "    print('****DEV')\n",
    "    # print(x_dev[:4,:])\n",
    "    print(y_dev[:4])\n",
    "\n",
    "    base_xgb_cfg = {\n",
    "        'n_estimators': 0,\n",
    "        'objective' : 'reg:squarederror',\n",
    "        'booster' : 'gbtree', #'gbtree'\n",
    "        'eta': 0.02,\n",
    "        'reg_lambda' : 0,\n",
    "    #     reg_alpha = 10,\n",
    "        'max_depth': 0,\n",
    "        'verbosity': 0,\n",
    "        'eval_metric' : 'rmse',# 'rmse', #'mlogloss',\n",
    "        'nthread': 3,\n",
    "        'rate_drop':0.,\n",
    "        'subsample': 1.0,\n",
    "\n",
    "    }\n",
    "\n",
    "    def model_cost(model_cfg):\n",
    "        xgb_cfg = copy.deepcopy(base_xgb_cfg)\n",
    "        xgb_cfg.update(\n",
    "            {\n",
    "            'n_estimators': model_cfg['n_estimators'],\n",
    "            'eta': model_cfg['eta'],\n",
    "            'reg_lambda' : model_cfg['reg_lambda'],\n",
    "            'max_depth': model_cfg['max_depth'],\n",
    "        }\n",
    "        )\n",
    "        # print(xgb_cfg)\n",
    "        model_now = xgb.XGBRFRegressor(**xgb_cfg)\n",
    "        model_now.fit(x_train, y_train, eval_set = [(x_dev, y_dev)])#, early_stopping_rounds=50, verbose=True)\n",
    "        dev_result = model_now.evals_result()\n",
    "        # y_dev_pred = model_now.predict(x_dev)\n",
    "        # dev_acc = acc_metric(y_dev_pred, y_dev)\n",
    "        v = dev_result['validation_0']['rmse'][0]\n",
    "        return v\n",
    "\n",
    "    search_space = {\n",
    "        'n_estimators': hp.randint('n_estimators', 2, 100),\n",
    "        'eta': hp.uniform('eta', 0.01, 1.0),\n",
    "        'max_depth': hp.randint('max_depth', 2, 6),\n",
    "        'reg_lambda': hp.randint('reg_lambda', 1, 20),\n",
    "    }\n",
    "    best = fmin(\n",
    "        fn = model_cost,\n",
    "        space = search_space,\n",
    "        algo = tpe.suggest,\n",
    "        max_evals = 20\n",
    "    )\n",
    "    print(best)\n",
    "\n",
    "    xgb_cfg = copy.deepcopy(base_xgb_cfg)\n",
    "    xgb_cfg.update(\n",
    "        {\n",
    "        'n_estimators': best['n_estimators'],\n",
    "        'eta': best['eta'],\n",
    "        'reg_lambda' : best['reg_lambda'],\n",
    "        'max_depth': best['max_depth'],\n",
    "    }\n",
    "    )\n",
    "    print(xgb_cfg)\n",
    "\n",
    "    model_now = xgb.XGBRFRegressor(**xgb_cfg)\n",
    "    model_now.fit(x_train, y_train, eval_set = [(x_dev, y_dev)])#, early_stopping_rounds=50, verbose=True)\n",
    "    dev_result=model_now.evals_result()\n",
    "    a = dev_result['validation_0']['rmse'][0]\n",
    "    # print(a)\n",
    "    model_now.save_model(save_model)\n",
    "    \n",
    "    # #report\n",
    "    tuning_report['model'] = 'xgb'\n",
    "    tuning_report['param'] = xgb_cfg\n",
    "\n",
    "    #evaluate model\n",
    "    model_now.load_model(save_model)\n",
    "    y_train_pred = model_now.predict(x_train)\n",
    "    acc = error_metric(y_train_pred, y_train)\n",
    "    print(f'train = {acc}')\n",
    "    tuning_report['metric'] = {'train': acc}\n",
    "    print('*** TRAIN ***')\n",
    "    print(list(zip(y_train_pred, y_train))[:10])\n",
    "    print('*** TRAIN ***')\n",
    "    \n",
    "    y_dev_pred = model_now.predict(x_dev)\n",
    "    dev_acc = error_metric(y_dev_pred, y_dev)\n",
    "    print(f'dev = {dev_acc}')\n",
    "    tuning_report['metric'].update({'dev': dev_acc})\n",
    "    \n",
    "    dev1 = list(zip(y_dev_pred, y_dev))\n",
    "    print(dev1[:5])\n",
    "\n",
    "    x_eval = train_dev_eval_set['eval'][feat_cols].to_numpy()\n",
    "    y_eval = train_dev_eval_set['eval'][label_cols].to_numpy()#.astype(int)\n",
    "    \n",
    "    y_eval_pred = model_now.predict(x_eval)\n",
    "    dev_acc = error_metric(y_eval_pred, y_eval)\n",
    "    print(f'dev = {dev_acc}')\n",
    "    tuning_report['metric'].update({'eval': dev_acc})\n",
    "\n",
    "\n",
    "    return tuning_report,dev1,list(zip(y_train_pred, y_train)),list(zip(y_eval_pred, y_eval))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b012a2d0-5289-43bc-be30-1a0f46d8cb65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****DEV\n",
      "[9.20965037 9.11346969 8.74873104 9.23463199]\n",
      "[0]\tvalidation_0-rmse:4.89332                                                   \n",
      "[0]\tvalidation_0-rmse:5.92280                                                   \n",
      "[0]\tvalidation_0-rmse:5.40551                                                   \n",
      "[0]\tvalidation_0-rmse:4.94343                                                   \n",
      "[0]\tvalidation_0-rmse:5.62281                                                   \n",
      "[0]\tvalidation_0-rmse:5.83282                                                   \n",
      "[0]\tvalidation_0-rmse:5.68359                                                   \n",
      "[0]\tvalidation_0-rmse:5.79120                                                   \n",
      "[0]\tvalidation_0-rmse:5.04199                                                   \n",
      "[0]\tvalidation_0-rmse:5.05273                                                   \n",
      "[0]\tvalidation_0-rmse:5.50638                                                   \n",
      "[0]\tvalidation_0-rmse:6.17268                                                   \n",
      "[0]\tvalidation_0-rmse:5.61819                                                   \n",
      "[0]\tvalidation_0-rmse:5.62549                                                   \n",
      "[0]\tvalidation_0-rmse:5.81598                                                   \n",
      "[0]\tvalidation_0-rmse:5.58289                                                   \n",
      "[0]\tvalidation_0-rmse:5.05121                                                   \n",
      "[0]\tvalidation_0-rmse:4.91594                                                   \n",
      "[0]\tvalidation_0-rmse:5.42440                                                   \n",
      "[0]\tvalidation_0-rmse:5.66153                                                   \n",
      "100%|██████████| 20/20 [00:01<00:00, 11.53trial/s, best loss: 4.893318846529976]\n",
      "{'eta': 0.17128452721900575, 'max_depth': 5, 'n_estimators': 78, 'reg_lambda': 3}\n",
      "{'n_estimators': 78, 'objective': 'reg:squarederror', 'booster': 'gbtree', 'eta': 0.17128452721900575, 'reg_lambda': 3, 'max_depth': 5, 'verbosity': 0, 'eval_metric': 'rmse', 'nthread': 3, 'rate_drop': 0.0, 'subsample': 1.0}\n",
      "[0]\tvalidation_0-rmse:4.89332\n",
      "train = 0.7129651072325236\n",
      "*** TRAIN ***\n",
      "[(0.6979651, 0.5610684764405991), (0.6979651, 0.5590420936862184), (0.6979651, 0.5604450015303859), (0.6979651, 0.572966135922389), (0.6979651, 0.5734075817655467), (0.6979651, 0.5805511464943209), (0.6979651, 0.5728878675141036), (0.6979651, 0.5805766031782246), (0.6979651, 0.5823955009408364), (0.6979651, 0.5804992556030812)]\n",
      "*** TRAIN ***\n",
      "dev = 4.893318884807616\n",
      "[(9.288963, 9.209650373946179), (9.288963, 9.113469692469302), (9.288963, 8.74873103721889), (9.77271, 9.234631989954348), (9.797572, 9.777993394386503)]\n",
      "dev = 36.82821886772536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gs/.local/share/virtualenvs/gs-KL75tqvG/lib/python3.8/site-packages/xgboost/sklearn.py:722: UserWarning: n_estimators is not saved in Scikit-Learn meta.\n",
      "  warnings.warn(str(k) + ' is not saved in Scikit-Learn meta.', UserWarning)\n",
      "/home/gs/.local/share/virtualenvs/gs-KL75tqvG/lib/python3.8/site-packages/xgboost/sklearn.py:722: UserWarning: max_depth is not saved in Scikit-Learn meta.\n",
      "  warnings.warn(str(k) + ' is not saved in Scikit-Learn meta.', UserWarning)\n",
      "/home/gs/.local/share/virtualenvs/gs-KL75tqvG/lib/python3.8/site-packages/xgboost/sklearn.py:722: UserWarning: reg_lambda is not saved in Scikit-Learn meta.\n",
      "  warnings.warn(str(k) + ' is not saved in Scikit-Learn meta.', UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier, Pool, cv\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from hyperopt import tpe, hp, fmin\n",
    "import copy\n",
    "# data_feat_hist['dev'].head(10)\n",
    "result = modelHyperOptTuningRegression('TQQQ', data_feat_hist, data, o_prediction_file=None, save_model = './xgb_model_debug.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "553351b3-769a-4f4c-a7e7-4ae220784b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     x\n",
      "a     \n",
      "0  2.0\n",
      "1  3.0\n",
      "2  2.0\n",
      "3  4.0\n",
      "   x\n",
      "a   \n",
      "0  1\n",
      "1  2\n",
      "2  3\n",
      "3  2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2.0, 3.0, 4.0}"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "a=pd.DataFrame({'x':[1,2,3,2,4]})\n",
    "# print(dir(a.index))\n",
    "a.index.name='a'\n",
    "b=a.shift(-1)\n",
    "b.dropna(inplace=True)\n",
    "# print(a)\n",
    "print(b)\n",
    "print(a.loc[b.index])\n",
    "c=b.gt(a.loc[b.index])\n",
    "set(b['x'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
