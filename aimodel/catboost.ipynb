{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "91a6bf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "target_symbol = 'TQQQ'\n",
    "cache_file = './TQQQ_stock_cache_feature.pkl'\n",
    "with open(cache_file, 'rb') as fi:\n",
    "    data_feature = pickle.load(fi)\n",
    "\n",
    "cache_raw_file = './TQQQ_stock_cache.pkl'\n",
    "with open(cache_raw_file, 'rb') as fi:\n",
    "    data_raw = pickle.load(fi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "26dfabbe",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'dayOfWeek0'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [71]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdata_feature\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdev\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdayOfWeek0\u001b[49m\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/gs-KL75tqvG/lib/python3.8/site-packages/pandas/core/generic.py:5487\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5480\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   5481\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[1;32m   5482\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[1;32m   5483\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[1;32m   5484\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[1;32m   5485\u001b[0m ):\n\u001b[1;32m   5486\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[0;32m-> 5487\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'dayOfWeek0'"
     ]
    }
   ],
   "source": [
    "data_feature['dev'].dayOfWeek0.astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dc5e86e3-c56e-4eb7-8b95-a3c1541d7ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Portfolio Value: 100.00                                                \n",
      "Final Portfolio Value: 114.19                                                   \n",
      "Starting Portfolio Value: 100.00                                                \n",
      "Final Portfolio Value: 96.64                                                    \n",
      "Starting Portfolio Value: 100.00                                                \n",
      "Final Portfolio Value: 102.67                                                   \n",
      "100%|██████████| 3/3 [00:05<00:00,  1.95s/trial, best loss: -14.185288339901035]\n",
      "**** This is 0-th try, {'depth': 5, 'iterations': 75, 'l2_leaf_reg': 9, 'learning_rate': 0.1724228504626181}\n",
      "Starting Portfolio Value: 100.00                                                \n",
      "Final Portfolio Value: 129.28                                                   \n",
      "Starting Portfolio Value: 100.00                                                \n",
      "Final Portfolio Value: 112.51                                                   \n",
      "Starting Portfolio Value: 100.00                                                \n",
      "Final Portfolio Value: 104.80                                                   \n",
      "100%|███████████| 3/3 [00:04<00:00,  1.62s/trial, best loss: -29.27985748135586]\n",
      "**** This is 1-th try, {'depth': 4, 'iterations': 98, 'l2_leaf_reg': 4, 'learning_rate': 0.6309296492607142}\n",
      "Starting Portfolio Value: 100.00                                                \n",
      "Final Portfolio Value: 109.11                                                   \n",
      "Starting Portfolio Value: 100.00                                                \n",
      "Final Portfolio Value: 99.48                                                    \n",
      "Starting Portfolio Value: 100.00                                                \n",
      "Final Portfolio Value: 102.67                                                   \n",
      "100%|████████████| 3/3 [00:04<00:00,  1.41s/trial, best loss: -9.11148331682395]\n",
      "**** This is 2-th try, {'depth': 2, 'iterations': 37, 'l2_leaf_reg': 3, 'learning_rate': 0.3048505518879919}\n",
      "{'iterations': 98, 'loss_function': 'MultiClass', 'use_best_model': True, 'verbose': False, 'learning_rate': 0.6309296492607142, 'l2_leaf_reg': 4, 'depth': 4, 'eval_metric': 'TotalF1'}\n",
      "train = 0.6339509263895844\n",
      "dev = 0.43769968051118213\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model': 'catboost',\n",
       " 'param': {'iterations': 98,\n",
       "  'loss_function': 'MultiClass',\n",
       "  'use_best_model': True,\n",
       "  'verbose': False,\n",
       "  'learning_rate': 0.6309296492607142,\n",
       "  'l2_leaf_reg': 4,\n",
       "  'depth': 4,\n",
       "  'eval_metric': 'TotalF1'},\n",
       " 'metric': {'train': 0.6339509263895844, 'dev': 0.43769968051118213}}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from prepareMLdata import prepareStockLabel\n",
    "import pickle\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier, Pool, cv\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from hyperopt import tpe, hp, fmin, Trials\n",
    "import copy\n",
    "from mlStrategyLongshort import strategyEvaluate\n",
    "import logging\n",
    "from melog import infome\n",
    "from mlPredict import dataSplit, acc_metric, error_metric, balanceLabel\n",
    "\n",
    "def modelHyperOptTuning(target_symbol, train_dev_eval_set, data_raw, o_prediction_file, save_model = './xgb_model.json', tune_obj_reward = {'n_stake':1, 'cash_capital':1000}):\n",
    "    '''\n",
    "    Desc: tune ML model\n",
    "\n",
    "    train_dev_eval_set: input train/dev/test data set\n",
    "\n",
    "    '''\n",
    "    tuning_report = {}\n",
    "\n",
    "    #step-1: model training\n",
    "    #prepare training data\n",
    "    train_dev_eval_set['train'], is_binary = balanceLabel(train_dev_eval_set['train'])\n",
    "    # train_dev_eval_set['dev'],is_binary = balanceLabel(train_dev_eval_set['dev'])\n",
    "\n",
    "    feat_cols = list(filter(lambda x: x != 'label', train_dev_eval_set['train'].columns))\n",
    "    label_cols = 'label'\n",
    "\n",
    "    x_train = train_dev_eval_set['train'][feat_cols].to_numpy()\n",
    "    y_train = train_dev_eval_set['train'][label_cols].to_numpy().astype(int)\n",
    "\n",
    "    x_dev = train_dev_eval_set['dev'][feat_cols].to_numpy()\n",
    "    y_dev = train_dev_eval_set['dev'][label_cols].to_numpy().astype(int)\n",
    "\n",
    "    eval_set_df = train_dev_eval_set['dev']\n",
    "    o_prediction_file = './opt_model_dev.csv'\n",
    "    \n",
    "#     is_binary = False\n",
    "    if is_binary:\n",
    "        loss_function = 'LogLoss'\n",
    "        eval_metric = 'Accuracy'\n",
    "    else:\n",
    "        loss_function = 'MultiClass'\n",
    "        eval_metric = 'TotalF1' # 'Accuracy' #F1\n",
    "    \n",
    "    base_catboost_cfg = {\n",
    "        'iterations': 0,\n",
    "        'loss_function' : loss_function,\n",
    "        # 'cat_features' : [],\n",
    "        'use_best_model': True,\n",
    "        'verbose': False,\n",
    "        'learning_rate': 0.01,\n",
    "        'l2_leaf_reg' : 0,\n",
    "    #     reg_alpha = 10,\n",
    "        'depth': 0,\n",
    "        'eval_metric' : eval_metric, #'auc', #'merror', #'mlogloss',\n",
    "\n",
    "    }\n",
    "\n",
    "    def model_cost(model_cfg):\n",
    "        catboost_cfg = copy.deepcopy(base_catboost_cfg)\n",
    "        catboost_cfg.update(\n",
    "            {\n",
    "            'iterations': model_cfg['iterations'],\n",
    "            'learning_rate': model_cfg['learning_rate'],\n",
    "            'l2_leaf_reg' : model_cfg['l2_leaf_reg'],\n",
    "            'depth': model_cfg['depth'],\n",
    "        }\n",
    "        )\n",
    "        # print(catboost_cfg)\n",
    "        model_now = CatBoostClassifier(**catboost_cfg)\n",
    "        model_now.fit(x_train, y_train, eval_set = [(x_dev, y_dev)])#, early_stopping_rounds=50, verbose=True)\n",
    "        y_dev_pred = model_now.predict(x_dev)\n",
    "#         dev_result = model_now.evals_result()\n",
    "#         dev_acc = dev_result['validation_0'][eval_metric][0]\n",
    "        dev_acc = acc_metric(y_dev_pred, y_dev)\n",
    "\n",
    "        #model predict in dev\n",
    "        feat_cols = list(filter(lambda x: x != 'label', eval_set_df.columns))\n",
    "        label_cols = 'label' \n",
    "        #evaluate set\n",
    "        x_eval = eval_set_df[feat_cols].to_numpy()\n",
    "        y_eval = eval_set_df[label_cols].to_numpy().astype(int)\n",
    "        y_eval_pred = model_now.predict(x_eval)\n",
    "        y_eval_pred_df = pd.DataFrame(eval_set_df['label'])\n",
    "        y_eval_pred_df['predict'] = y_eval_pred\n",
    "        #Save prediction \n",
    "        o_cols = ['Open', 'High', 'Low','Close', 'Adj Close', 'Volume',]\n",
    "        \n",
    "        o_test = data_raw[target_symbol].loc[y_eval_pred_df.index][o_cols]\n",
    "        o_test['openinterest'] = 0\n",
    "        o_test = pd.merge(o_test, y_eval_pred_df['predict'], on='Date', how='inner')\n",
    "        o_test.to_csv(o_prediction_file, index = True)\n",
    "        reward_gain = strategyEvaluate(target_symbol, o_prediction_file, n_stake=1, cash_capital= 100, is_model_opt=True)\n",
    "\n",
    "        return -reward_gain #dev_acc #\n",
    "\n",
    "    search_space = {\n",
    "        'iterations': hp.randint('iterations', 5, 100),\n",
    "        'learning_rate': hp.uniform('learning_rate', 0.01, 1),\n",
    "        'depth': hp.randint('depth', 2, 8),\n",
    "        'l2_leaf_reg': hp.randint('l2_leaf_reg', 1, 10),\n",
    "    }\n",
    "    best_model = None\n",
    "    best_model_val = None\n",
    "    n_cycle = 0\n",
    "    while(True):\n",
    "        for ntry in range(3):\n",
    "            opt_trials = Trials()\n",
    "            best = fmin(\n",
    "                fn = model_cost,\n",
    "                space = search_space,\n",
    "                algo = tpe.suggest,\n",
    "                max_evals = 3,\n",
    "                trials=opt_trials,        \n",
    "            )\n",
    "#             logging.info(infome(__file__, '*** XGB MODEL tuinig *** '))\n",
    "            best_value = sorted(opt_trials.results, key = lambda v: v['loss'])\n",
    "#             logging.info(infome(__file__, f'best = {best}, {best_value[0]} '))\n",
    "\n",
    "            if best_model:\n",
    "                if best_value[0]['loss'] < best_model_val['loss']:\n",
    "                    best_model_val = best_value[0]\n",
    "                    best_model = best\n",
    "            else:\n",
    "                best_model_val = best_value[0]\n",
    "                best_model = best\n",
    "\n",
    "            print(f'**** This is {ntry}-th try, {best}')\n",
    "        if best_value[0]['loss'] < 0.0 or n_cycle >=3:\n",
    "            break\n",
    "        n_cycle += 1\n",
    "\n",
    "    catboost_cfg = copy.deepcopy(base_catboost_cfg)\n",
    "    catboost_cfg.update(\n",
    "        {\n",
    "        'iterations': best_model['iterations'],\n",
    "        'learning_rate': best_model['learning_rate'],\n",
    "        'l2_leaf_reg' : best_model['l2_leaf_reg'],\n",
    "        'depth': best_model['depth'],\n",
    "    }\n",
    "    )\n",
    "    print(catboost_cfg)\n",
    "    model_now = CatBoostClassifier(**catboost_cfg)\n",
    "    model_now.fit(x_train, y_train, eval_set = [(x_dev, y_dev)])#, early_stopping_rounds=50, verbose=True)\n",
    " \n",
    "    model_now.save_model(save_model)\n",
    "    \n",
    "    # #report\n",
    "    tuning_report['model'] = 'catboost'\n",
    "    tuning_report['param'] = catboost_cfg\n",
    "\n",
    "    #evaluate model\n",
    "    model_now.load_model(save_model)\n",
    "    y_train_pred = model_now.predict(x_train)\n",
    "    acc = acc_metric(y_train_pred, y_train)\n",
    "    print(f'train = {acc}')\n",
    "    tuning_report['metric'] = {'train': acc}\n",
    "    \n",
    "    y_dev_pred = model_now.predict(x_dev)\n",
    "    dev_acc = acc_metric(y_dev_pred, y_dev)\n",
    "    print(f'dev = {dev_acc}')\n",
    "    tuning_report['metric'].update({'dev': dev_acc})\n",
    " \n",
    "\n",
    "    return tuning_report\n",
    "\n",
    "modelHyperOptTuning('TQQQ', data_feature, data_raw, './catboost_dev.csv', save_model = './catboost_model.json', tune_obj_reward = {'n_stake':1, 'cash_capital':1000})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4880f3c9-243a-4554-aba8-cdf3ab653583",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_feat_hist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [57]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# print(feat_data2['price_mid'].head(3))\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# print(feat_data2['price_mid'].shift(-1).head(3))\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# a=feat_data2['price_mid'].shift(-1)-feat_data2['price_mid']\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdata_feat_hist\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdev\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mindex)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_feat_hist' is not defined"
     ]
    }
   ],
   "source": [
    "# print(feat_data2['price_mid'].head(3))\n",
    "# print(feat_data2['price_mid'].shift(-1).head(3))\n",
    "# a=feat_data2['price_mid'].shift(-1)-feat_data2['price_mid']\n",
    "print(data_feat_hist['dev'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2a499fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███| 100/100 [00:00<00:00, 501.22trial/s, best loss: 0.0026426603445583396]\n",
      "{'x': 0.051406812238830174}\n",
      "****\n",
      "{'loss': 0.0026426603445583396, 'status': 'ok', 'eval_time': 1665208408.1580944, 'other_stuff': {'type': None, 'value': [0, 1, 2]}}\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import time\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "\n",
    "def objective(x):\n",
    "    return {\n",
    "        'loss': x ** 2,\n",
    "        'status': STATUS_OK,\n",
    "        # -- store other results like this\n",
    "        'eval_time': time.time(),\n",
    "        'other_stuff': {'type': None, 'value': [0, 1, 2]},\n",
    "        # -- attachments are handled differently\n",
    "        'attachments':\n",
    "            {'time_module': pickle.dumps(time.time)}\n",
    "        }\n",
    "trials = Trials()\n",
    "best = fmin(objective,\n",
    "    space=hp.uniform('x', -10, 10),\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=100,\n",
    "    trials=trials)\n",
    "print(best)\n",
    "print('****')\n",
    "# print(trials.results)\n",
    "d = sorted(trials.results, key = lambda v: v['loss'])\n",
    "print(d[0])\n",
    "# print(trials.trials[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "46de4c5b-a93b-41d8-8830-a331a2a57a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_metric(y1, y2):\n",
    "    '''\n",
    "    Calculate accuracy\n",
    "    '''\n",
    "    res = list(zip(y1, y2))\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for v in res:\n",
    "        correct += (v[0]-v[1]) * (v[0]-v[1])\n",
    "\n",
    "    return math.sqrt(correct/float(len(res)))\n",
    "\n",
    "\n",
    "def modelHyperOptTuningRegression(target_symbol, train_dev_eval_set, data_raw, o_prediction_file, save_model = './xgb_model_debug.json'):\n",
    "    '''\n",
    "    Desc: tune ML model\n",
    "\n",
    "    train_dev_eval_set: input train/dev/test data set\n",
    "\n",
    "    '''\n",
    "    tuning_report = {}\n",
    "\n",
    "    #step-1: model training\n",
    "    #prepare training data\n",
    "    # train_dev_eval_set['train'] = balanceLabel(train_dev_eval_set['train'])\n",
    "    # train_dev_eval_set['dev'] = balanceLabel(train_dev_eval_set['dev'])\n",
    "\n",
    "    feat_cols = list(filter(lambda x: x != 'label', train_dev_eval_set['train'].columns))\n",
    "    label_cols = 'label'\n",
    "\n",
    "    x_train = train_dev_eval_set['train'][feat_cols].to_numpy()\n",
    "    y_train = train_dev_eval_set['train'][label_cols].to_numpy()#.astype(int)\n",
    "\n",
    "    x_dev = train_dev_eval_set['dev'][feat_cols].to_numpy()\n",
    "    y_dev = train_dev_eval_set['dev'][label_cols].to_numpy()#.astype(int)\n",
    "\n",
    "    print('****DEV')\n",
    "    # print(x_dev[:4,:])\n",
    "    print(y_dev[:4])\n",
    "\n",
    "    base_xgb_cfg = {\n",
    "        'n_estimators': 0,\n",
    "        'objective' : 'reg:squarederror',\n",
    "        'booster' : 'gbtree', #'gbtree'\n",
    "        'eta': 0.02,\n",
    "        'reg_lambda' : 0,\n",
    "    #     reg_alpha = 10,\n",
    "        'max_depth': 0,\n",
    "        'verbosity': 0,\n",
    "        'eval_metric' : 'rmse',# 'rmse', #'mlogloss',\n",
    "        'nthread': 3,\n",
    "        'rate_drop':0.,\n",
    "        'subsample': 1.0,\n",
    "\n",
    "    }\n",
    "\n",
    "    def model_cost(model_cfg):\n",
    "        xgb_cfg = copy.deepcopy(base_xgb_cfg)\n",
    "        xgb_cfg.update(\n",
    "            {\n",
    "            'n_estimators': model_cfg['n_estimators'],\n",
    "            'eta': model_cfg['eta'],\n",
    "            'reg_lambda' : model_cfg['reg_lambda'],\n",
    "            'max_depth': model_cfg['max_depth'],\n",
    "        }\n",
    "        )\n",
    "        # print(xgb_cfg)\n",
    "        model_now = xgb.XGBRFRegressor(**xgb_cfg)\n",
    "        model_now.fit(x_train, y_train, eval_set = [(x_dev, y_dev)])#, early_stopping_rounds=50, verbose=True)\n",
    "        dev_result = model_now.evals_result()\n",
    "        # y_dev_pred = model_now.predict(x_dev)\n",
    "        # dev_acc = acc_metric(y_dev_pred, y_dev)\n",
    "        v = dev_result['validation_0']['rmse'][0]\n",
    "        return v\n",
    "\n",
    "    search_space = {\n",
    "        'n_estimators': hp.randint('n_estimators', 2, 100),\n",
    "        'eta': hp.uniform('eta', 0.01, 1.0),\n",
    "        'max_depth': hp.randint('max_depth', 2, 6),\n",
    "        'reg_lambda': hp.randint('reg_lambda', 1, 20),\n",
    "    }\n",
    "    best = fmin(\n",
    "        fn = model_cost,\n",
    "        space = search_space,\n",
    "        algo = tpe.suggest,\n",
    "        max_evals = 20\n",
    "    )\n",
    "    print(best)\n",
    "\n",
    "    xgb_cfg = copy.deepcopy(base_xgb_cfg)\n",
    "    xgb_cfg.update(\n",
    "        {\n",
    "        'n_estimators': best['n_estimators'],\n",
    "        'eta': best['eta'],\n",
    "        'reg_lambda' : best['reg_lambda'],\n",
    "        'max_depth': best['max_depth'],\n",
    "    }\n",
    "    )\n",
    "    print(xgb_cfg)\n",
    "\n",
    "    model_now = xgb.XGBRFRegressor(**xgb_cfg)\n",
    "    model_now.fit(x_train, y_train, eval_set = [(x_dev, y_dev)])#, early_stopping_rounds=50, verbose=True)\n",
    "    dev_result=model_now.evals_result()\n",
    "    a = dev_result['validation_0']['rmse'][0]\n",
    "    # print(a)\n",
    "    model_now.save_model(save_model)\n",
    "    \n",
    "    # #report\n",
    "    tuning_report['model'] = 'xgb'\n",
    "    tuning_report['param'] = xgb_cfg\n",
    "\n",
    "    #evaluate model\n",
    "    model_now.load_model(save_model)\n",
    "    y_train_pred = model_now.predict(x_train)\n",
    "    acc = error_metric(y_train_pred, y_train)\n",
    "    print(f'train = {acc}')\n",
    "    tuning_report['metric'] = {'train': acc}\n",
    "    print('*** TRAIN ***')\n",
    "    print(list(zip(y_train_pred, y_train))[:10])\n",
    "    print('*** TRAIN ***')\n",
    "    \n",
    "    y_dev_pred = model_now.predict(x_dev)\n",
    "    dev_acc = error_metric(y_dev_pred, y_dev)\n",
    "    print(f'dev = {dev_acc}')\n",
    "    tuning_report['metric'].update({'dev': dev_acc})\n",
    "    \n",
    "    dev1 = list(zip(y_dev_pred, y_dev))\n",
    "    print(dev1[:5])\n",
    "\n",
    "    x_eval = train_dev_eval_set['eval'][feat_cols].to_numpy()\n",
    "    y_eval = train_dev_eval_set['eval'][label_cols].to_numpy()#.astype(int)\n",
    "    \n",
    "    y_eval_pred = model_now.predict(x_eval)\n",
    "    dev_acc = error_metric(y_eval_pred, y_eval)\n",
    "    print(f'dev = {dev_acc}')\n",
    "    tuning_report['metric'].update({'eval': dev_acc})\n",
    "\n",
    "\n",
    "    return tuning_report,dev1,list(zip(y_train_pred, y_train)),list(zip(y_eval_pred, y_eval))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b012a2d0-5289-43bc-be30-1a0f46d8cb65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****DEV\n",
      "[9.20965037 9.11346969 8.74873104 9.23463199]\n",
      "[0]\tvalidation_0-rmse:4.89332                                                   \n",
      "[0]\tvalidation_0-rmse:5.92280                                                   \n",
      "[0]\tvalidation_0-rmse:5.40551                                                   \n",
      "[0]\tvalidation_0-rmse:4.94343                                                   \n",
      "[0]\tvalidation_0-rmse:5.62281                                                   \n",
      "[0]\tvalidation_0-rmse:5.83282                                                   \n",
      "[0]\tvalidation_0-rmse:5.68359                                                   \n",
      "[0]\tvalidation_0-rmse:5.79120                                                   \n",
      "[0]\tvalidation_0-rmse:5.04199                                                   \n",
      "[0]\tvalidation_0-rmse:5.05273                                                   \n",
      "[0]\tvalidation_0-rmse:5.50638                                                   \n",
      "[0]\tvalidation_0-rmse:6.17268                                                   \n",
      "[0]\tvalidation_0-rmse:5.61819                                                   \n",
      "[0]\tvalidation_0-rmse:5.62549                                                   \n",
      "[0]\tvalidation_0-rmse:5.81598                                                   \n",
      "[0]\tvalidation_0-rmse:5.58289                                                   \n",
      "[0]\tvalidation_0-rmse:5.05121                                                   \n",
      "[0]\tvalidation_0-rmse:4.91594                                                   \n",
      "[0]\tvalidation_0-rmse:5.42440                                                   \n",
      "[0]\tvalidation_0-rmse:5.66153                                                   \n",
      "100%|██████████| 20/20 [00:01<00:00, 11.53trial/s, best loss: 4.893318846529976]\n",
      "{'eta': 0.17128452721900575, 'max_depth': 5, 'n_estimators': 78, 'reg_lambda': 3}\n",
      "{'n_estimators': 78, 'objective': 'reg:squarederror', 'booster': 'gbtree', 'eta': 0.17128452721900575, 'reg_lambda': 3, 'max_depth': 5, 'verbosity': 0, 'eval_metric': 'rmse', 'nthread': 3, 'rate_drop': 0.0, 'subsample': 1.0}\n",
      "[0]\tvalidation_0-rmse:4.89332\n",
      "train = 0.7129651072325236\n",
      "*** TRAIN ***\n",
      "[(0.6979651, 0.5610684764405991), (0.6979651, 0.5590420936862184), (0.6979651, 0.5604450015303859), (0.6979651, 0.572966135922389), (0.6979651, 0.5734075817655467), (0.6979651, 0.5805511464943209), (0.6979651, 0.5728878675141036), (0.6979651, 0.5805766031782246), (0.6979651, 0.5823955009408364), (0.6979651, 0.5804992556030812)]\n",
      "*** TRAIN ***\n",
      "dev = 4.893318884807616\n",
      "[(9.288963, 9.209650373946179), (9.288963, 9.113469692469302), (9.288963, 8.74873103721889), (9.77271, 9.234631989954348), (9.797572, 9.777993394386503)]\n",
      "dev = 36.82821886772536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gs/.local/share/virtualenvs/gs-KL75tqvG/lib/python3.8/site-packages/xgboost/sklearn.py:722: UserWarning: n_estimators is not saved in Scikit-Learn meta.\n",
      "  warnings.warn(str(k) + ' is not saved in Scikit-Learn meta.', UserWarning)\n",
      "/home/gs/.local/share/virtualenvs/gs-KL75tqvG/lib/python3.8/site-packages/xgboost/sklearn.py:722: UserWarning: max_depth is not saved in Scikit-Learn meta.\n",
      "  warnings.warn(str(k) + ' is not saved in Scikit-Learn meta.', UserWarning)\n",
      "/home/gs/.local/share/virtualenvs/gs-KL75tqvG/lib/python3.8/site-packages/xgboost/sklearn.py:722: UserWarning: reg_lambda is not saved in Scikit-Learn meta.\n",
      "  warnings.warn(str(k) + ' is not saved in Scikit-Learn meta.', UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier, Pool, cv\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from hyperopt import tpe, hp, fmin\n",
    "import copy\n",
    "# data_feat_hist['dev'].head(10)\n",
    "result = modelHyperOptTuningRegression('TQQQ', data_feat_hist, data, o_prediction_file=None, save_model = './xgb_model_debug.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "553351b3-769a-4f4c-a7e7-4ae220784b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     x\n",
      "a     \n",
      "0  2.0\n",
      "1  3.0\n",
      "2  2.0\n",
      "3  4.0\n",
      "   x\n",
      "a   \n",
      "0  1\n",
      "1  2\n",
      "2  3\n",
      "3  2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2.0, 3.0, 4.0}"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "a=pd.DataFrame({'x':[1,2,3,2,4]})\n",
    "# print(dir(a.index))\n",
    "a.index.name='a'\n",
    "b=a.shift(-1)\n",
    "b.dropna(inplace=True)\n",
    "# print(a)\n",
    "print(b)\n",
    "print(a.loc[b.index])\n",
    "c=b.gt(a.loc[b.index])\n",
    "set(b['x'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
